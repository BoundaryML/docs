## What is Gloo?

Gloo is a toolkit that allows you to build and monitor LLM (or other ML model) pipelines using a **function-based** architecture, where every call to a model has a defined input and output schema. Gloo uses a unique language (GlooLang) to build your LLM functions in a few lines of code.

If you’re building a chatbot, or any LLM application Gloo is a good way to decompose your task into specific observable tasks (classification, entity extraction, etc).

<iframe
  width="560"
  height="315"
  src="https://www.youtube.com/embed/fpWbMp6jz0U?si=Dn56Mp_PlBaQ9YzB"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
  allowfullscreen
></iframe>

Gloo consists of the following parts:

1. **Gloo Lang -** Human-readable schema designed to declare your LLM functions and their inputs and outputs.
2. **Gloo Intellisense VSCode Extension -** Enables GlooLang intellisense in VSCode
3. **Gloo CLI -** Builds gloo-lang files into executable functions for Python (and soon Typescript).
4. **Gloo Dashboard -** A dashboard where you can see Gloo-generated telemetry, like function call failure rates, etc.

### Example Schema

Example Gloo Schema for a sentiment classifier using an LLM

<img src="/images/classify-sentiment-bool-llm-variant.png" />

(See sections below to learn how it works)

Gloo saves hundreds of lines of code in telemetry, serialization and deserialization logic.

## Getting started

### Pre-requirements

Currently Gloo only supports Python, with the [Poetry](https://python-poetry.org/docs/) package manager. If you're using pip instead of poetry, reach out and we can help you set up.

For updates on Typescript release, feel free to reach out at contact@trygloo.com

### Create a Gloo Project in the dashboard

Visit [beta.app.trygloo.com](https://beta.app.trygloo.com) and create a new project.

#### Setup environment variables

On the dashboard, click on the project you created and go to "Keys". Note down the project ID and create a new secret to use as the APP SECRET below.

```bash
GLOO_APP_ID=proj_123...
GLOO_APP_SECRET=gloo:your-key-from-dashboard
OPENAI_API_KEY=your-open-ai-key
# temporarily redirect to beta (production deployment coming soon)
GLOO_BASE_URL=https://beta.app.trygloo.com/api
```

### Install the **Gloo CLI**

```
brew tap gloohq/gloo
brew install gloo
```

To update the CLI

```
brew update
brew upgrade gloo
```

### Install the **Gloo VSCode Extension**

Search for gloo.gloo in the VSCode extension marketplace

![Gloo Intellisense](/images/extension.png)

### Initialize Gloo in your project

```
gloo init
```

![](/images/glooinit.png)

### Folder structure

```
.
├── app
│   └── your application files
├── gloo
│   └── your gloo files live here
├── pyproject.toml
└── generated
    └── translated, runnable python code from .gloo.
          Don't edit these files.
```

## Gloo Lang Deep dive (5 min read)

### Functions

Functions (and other unique types on GlooLang) start with an **@** symbol. They are the building blocks of your LLM pipeline.

<img height="400" width="400" src="/images/function-classify-bool.png" />

### Variants

Variants specify how functions are executed. Functions are the blueprint as to what type of data they accept and return, and variants are the implementation of those functions.

The following is an **LLM Variant** that prompts the model to take a string and return a boolean.

<img src="/images/classify-sentiment-bool-llm-variant.png" />

### Running a function

To run a function in your code you have to import it from the generated folder. The generated folder is where the Gloo CLI translates your GlooLang files into runnable Python code.

<Note>
  The generated functions are async by default. You can use asyncio to make them
  run synchronously{" "}
</Note>

<img src="/images/running-yourself.png" />

Press `control + space` on VSCode to get suggestions for all the functions you can run.

<img src="/images/control-space-suggestions.png" />

### Testing

Gloo makes it easy to add function tests by declaring a test_group like below:

<img src="/images/test-group1.png" />

These get automatically compiled into Python code that you can run using pytest.

You can declare as many different test groups as you want for a function. Each test group runs all variants of the function that have been declared.

E.g. if you have 3 versions of a prompt, running the test will run all 3 variants so you can compare results.

Note the **curly syntax** on Gloo:

- inline data does not require \{\}
- multi-line strings or data requires \{\}

To run the test execute `pytest -s -k MyTests` in your terminal.

<img src="/images/test-run-bool.png" />

and view the results on the dashboard using the link

<img src="/images/dashboardtest1.png" />

#### Test assertions

To assert a certain result from the output, declare a **@method** for your **@test_group** that takes in 2 special types: **InputType** and **OutputType**, which are the input and output types of your function. You can then use the **assert** keyword to assert a certain result.

<img src="/images/test-group-validate.png" />

<Card title="Inlining Python code" icon="lightbulb" iconType="duotone" color="#ca8b04">
On GlooLang, you can write in-line python code using the **@lang[py]** identifier under **@method** statements. This gets copied to into the generated boilerplate code under `/generated`

</Card>

<Tip>
  We recommend writing the python functions in an actual python file and copying
  them over. We are working on syntax highlighting and linting for these
  statements.
</Tip>

### Prompt engineering on Gloo

#### Basic example

The prompt can take a multi-line string inside a \{\} block. No need to escape common characters like quotes. If you want to escape a curly brace, use \{\{ and \}\}.

The prompt can leverage two special variables, the **@input** and **@output**.

The **@input** allows you to inject your input into the prompt. If your input is an object, you can access its properties using dot notation, such as **\{@input.text\}**.

The **@output** allows you to inject the output schema using **\{@output.json\}**

See the below Example for a prompt defined inside an @variant\[llm\] for a function.

<img src="/images/extract-verbs/extract-verbs-nouns-example.png" />

and the end result

<img src="/images/extract-verbs/extract-verbs-prompt-dash.png" />

#### Modifying the output schema descriptions

LLMs can use descriptions to figure out what to inject into each field in your output schema. In GlooLang we can accomplish
this by using the @stringify keyword, which only works on the Function's @output types.
